{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "## Setting Up the Environment\r\n",
    "\r\n",
    "In this cell, we're installing a number of important Python packages that we'll need throughout this notebook. These packages are all part of the broader Python scientific computing ecosystem, and are widely used in machine learning and data science.\r\n",
    "\r\n",
    "1. **PyTorch** (`torch`): This is the main package we'll be using. PyTorch is a popular machine learning library which provides a wide range of features for building and training neural networks. It has strong GPU acceleration support and is used by many researchers in the field.\r\n",
    "\r\n",
    "2. **Torchvision** (`torchvision`): This package is a part of the PyTorch project. It provides useful utilities for working with image data, including pre-trained models, datasets, and image transformation tools.\r\n",
    "\r\n",
    "3. **PyTorch Lightning** (`pytorch-lightning`): This is a wrapper around PyTorch that simplifies a lot of the boilerplate code we often find ourselves writing. It structures your PyTorch code in a way that is consistent and makes it easier to do things like distributed training and automatic mixed precision.\r\n",
    "\r\n",
    "4. **PyTorch Lightning Bolts** (`pytorch-lightning-bolts`): Bolts is an extension of PyTorch Lightning that provides a number of pre-made models, datasets, and other utilities. It's great for getting a quick start with new projects.\r\n",
    "\r\n",
    "5. **NumPy** (`numpy`): This is a fundamental package for scientific computing in Python. It provides a powerful N-dimensional array object and functions for working with these arrays.\r\n",
    "\r\n",
    "6. **Pandas** (`pandas`): This package provides high-performance, easy-to-use data structures and data analysis tools. We'll be using it for data manipulation and analysis.\r\n",
    "\r\n",
    "7. **Matplotlib** (`matplotlib`): This is a plotting library for Python and its numerical mathematics extension NumPy. We'll use it to create graphs and visualize our data and results.\r\n",
    "\r\n",
    "8. **OpenCV** (`opencv-python`): This is an open source computer vision and machine learning software library. We'll use it for processing and manipulating images.\r\n",
    "\r\n",
    "9. **Scikit-Learn** (`scikit-learn`): This is a powerful library for machine learning in Python. It provides a selection of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction via a consistence interface in Python.\r\n",
    "\r\n",
    "10. **TensorBoardX** (`tensorboardX`): This package lets you use TensorBoard with PyTorch, TensorFlow's visualization toolkit. It's great for visualizing training progress, debugging, and optimizing your models.\r\n",
    "\r\n",
    "11. **TensorBoard** (`tensorboard`): TensorBoard provides the visualization and tooling needed for machine learning experimentation. You can track and visualize metrics such as loss and accuracy, visualize the model graph, view histograms, display images, and much more.\r\n",
    "\r\n",
    "Running the `!pip install` command installs these packages so that they can be imported and used in Python programs. The exclamation point at the beginning of the line is a special Jupyter command that allows us to run command-line instructions from inside a notebook. \r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "In the next cell, we'll start importing these packages and using them to build our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/jbourne/anaconda3/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in /home/jbourne/anaconda3/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: pytorch-lightning in /home/jbourne/anaconda3/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: pytorch-lightning-bolts in /home/jbourne/anaconda3/lib/python3.10/site-packages (0.3.2.post1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: sympy in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: jinja2 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: typing-extensions in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (4.6.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: networkx in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: filelock in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: setuptools in /home/jbourne/anaconda3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/jbourne/anaconda3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: lit in /home/jbourne/anaconda3/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: cmake in /home/jbourne/anaconda3/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.26.4)\n",
      "Requirement already satisfied: requests in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torchvision) (2.29.0)\n",
      "Requirement already satisfied: numpy in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.7.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (0.8.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (2023.6.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (0.11.4)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (23.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
      "Requirement already satisfied: numpy in /home/jbourne/anaconda3/lib/python3.10/site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in /home/jbourne/anaconda3/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in /home/jbourne/anaconda3/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: opencv-python in /home/jbourne/anaconda3/lib/python3.10/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: scikit-learn in /home/jbourne/anaconda3/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: tensorboardX in /home/jbourne/anaconda3/lib/python3.10/site-packages (2.6)\n",
      "Requirement already satisfied: tensorboard in /home/jbourne/anaconda3/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from matplotlib) (4.40.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.8.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from tensorboardX) (3.20.3)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from tensorboard) (1.54.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from tensorboard) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from tensorboard) (3.4.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from tensorboard) (65.6.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from tensorboard) (0.38.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from tensorboard) (2.29.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from tensorboard) (2.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from tensorboard) (0.7.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.1)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.26.15)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/jbourne/anaconda3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision pytorch-lightning pytorch-lightning-bolts\n",
    "!pip install numpy pandas matplotlib opencv-python scikit-learn tensorboardX tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries**\r\n",
    "\r\n",
    "This cell imports all the necessary libraries we'll be using in this notebook.\r\n",
    "\r\n",
    "- **Standard library**:\r\n",
    "  - `os`: This module provides a portable way of using operating system dependent functionality.\r\n",
    "\r\n",
    "- **Third-party libraries**:\r\n",
    "  - `numpy` and `pandas`: These are fundamental packages for scientific computing and data manipulation in Python.\r\n",
    "  - `matplotlib.pyplot`: This library is used for creating static, animated, and interactive visualizations in Python.\r\n",
    "  - `PIL.Image`: The Python Imaging Library adds image processing capabilities to your Python interpreter.\r\n",
    "  - `sklearn.model_selection.train_test_split`: This function is a quick utility that wraps input validation and next(ShuffleSplit().split(X, y)) and application to input data into a single call for splitting data in a oner.\r\n",
    "  - `sklearn`: Scikit-learn is a free software machine learning library for the Python programming language.\r\n",
    "\r\n",
    "- **PyTorch and related libraries**:\r\n",
    "  - `torch`, `torchvision`, `torch.nn`, `torch.utils.data`, `torch.optim`: These are libraries from PyTorch used for building neural networks, data loading, and optimization.\r\n",
    "  \r\n",
    "- **PyTorch Lightning**:\r\n",
    "  - `pytorch_lightning`: PyTorch Lightning is a lightweight PyTorch wrapper for high-performance AI research. It organizes your code base, decouples your research into four intuitive categories while providing full flexibility with all the benefits of PyTorch, reducing the boilerplate so you can focus on the key parts of your code.\r\n",
    "\r\n",
    "- **Printing versions**: This ensures we know the versions of the libraries we are working with. Having this information is valuable for reproducibility and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torchvision: 0.15.2+cu117\n",
      "Torchvision Lightening: 2.0.3\n",
      "Torch: 2.0.1+cu117\n",
      "Numpy: 1.24.3\n",
      "Pandas: 2.0.2\n",
      "Sklearn: 1.2.2\n"
     ]
    }
   ],
   "source": [
    "# Standard library\n",
    "import os\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "# PyTorch and related libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, DeviceStatsMonitor, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "\n",
    "# Print versions\n",
    "print(f\"Torchvision: {torchvision.__version__}\")\n",
    "print(f\"Torchvision Lightening: {pl.__version__}\")\n",
    "print(f\"Torch: {torch.__version__}\")\n",
    "print(f\"Numpy: {np.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"Sklearn: {sklearn.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up Constants**\r\n",
    "\r\n",
    "This cell defines all the constants that will be used throughout the notebook.\r\n",
    "\r\n",
    "- **Path to data**:\r\n",
    "  - `DATA_DIR`: This is the directory where your data is stored.\r\n",
    "  - `KEY_DATA_DIR`: This directory contains key slices of the dataset.\r\n",
    "  - `CSV_PATH`: This is the path to the CSV file which contains labels for the images.\r\n",
    "\r\n",
    "- **Image settings**:\r\n",
    "  - `IMAGE_SIZE`: We resize all images to this size. Many pre-trained models, like ResNet, expect this input size.\r\n",
    "  - `NUM_CLASSES`: This denotes the number of unique classes or labels in our dataset.\r\n",
    "\r\n",
    "- **Normalization constants for ImageNet**:\r\n",
    "  - `IMAGENET_MEAN` and `IMAGENET_STD`: These are normalization constants used for ImageNet. We will use these constants to normalize our own dataset as the model we are using (ResNet) was trained on ImageNet.\r\n",
    "\r\n",
    "- **Training settings**:\r\n",
    "  - `BATCH_SIZE`: This is the number of samples that will be propagated through the network at one time.\r\n",
    "  - `EPOCHS`: This is the number of complete passes through the entire training dataset.\r\n",
    "  - `LEARNING_RATE`: This controls how much to change the model in response to the estimated error each time the model weights are updated.\r\n",
    "  - `TRAIN_SPLIT`: This is the proportion of data to use for training. The rest will be used for validation.\r\n",
    "\r\n",
    "- **CPU settings**:\r\n",
    "  - `CPU_CORES`: The number of CPU cores to use for data loading.\r\n",
    "\r\n",
    "- **Optimizer settings**:\r\n",
    "  - `OPTIMIZER`: This is the optimization algorithm used to change the attributes of the neural network such as weights and learning rate to reduce the losses.\r\n",
    "\r\n",
    "Lastly, we print out these constants to make sure they are set correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jbourne/projects/bourne/reagan/deep_lesion/data/Images_png\n",
      "/home/jbourne/projects/bourne/reagan/deep_lesion/data/Key_slices\n",
      "/home/jbourne/projects/bourne/reagan/deep_lesion/data/DL_info.csv\n",
      "32\n",
      "9\n",
      "Adam\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "\n",
    "# Path to data\n",
    "DATA_DIR: str = os.path.join(os.getcwd(), 'data/Images_png')\n",
    "KEY_DATA_DIR: str = os.path.join(os.getcwd(), 'data/Key_slices')\n",
    "CSV_PATH: str = os.path.join(os.getcwd(), 'data/DL_info.csv')  # The path to the CSV file containing the labels\n",
    "\n",
    "# Image settings\n",
    "IMAGE_SIZE: int = 224  # We will resize all images to this size. ResNet, for example, expects this input size\n",
    "NUM_CLASSES: int = 10   # Number of different lesions\n",
    "\n",
    "# Normalization constants for ImageNet\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Training settings\n",
    "BATCH_SIZE: int = 32  # The batch size for training and validation\n",
    "EPOCHS: int = 9  # The number of epochs for training. Adjust based on your observation of the model performance\n",
    "LEARNING_RATE: float = 1e-3  # Learning rate for the optimizer. This may need to be adjusted based on the model's performance\n",
    "TRAIN_SPLIT: float = 0.8  # The proportion of data to use for training. The rest will be used for validation\n",
    "CPU_CORES: int = 10\n",
    "\n",
    "# Optimizer settings\n",
    "OPTIMIZER: str = 'Adam'  # The optimizer to use. You can change this to 'SGD' or other optimizers as needed\n",
    "\n",
    "print(DATA_DIR)\n",
    "print(KEY_DATA_DIR)\n",
    "print(CSV_PATH)\n",
    "print(BATCH_SIZE)\n",
    "print(EPOCHS)\n",
    "print(OPTIMIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the Model**\r\n",
    "\r\n",
    "This is the main section where we define our model. In this case, we're using a technique known as **transfer learning**, which is a method where a pre-trained model is adapted for a new, different data problem. Here we use the **ResNet50** model, which is a convolutional neural network that is 50 layers deep, pre-trained on the ImageNet dataset.\r\n",
    "\r\n",
    "In the following sections, we will discuss each part of the `DeepLesionModel` class.\r\n",
    "\r\n",
    "- **`__init__`**: This is the initialization function where we define our model architecture and loss function.\r\n",
    "  - We initialize a pre-trained ResNet50 model.\r\n",
    "  - We replace the last layer (fully connected layer) of ResNet50 to match the number of classes in our problem (`num_classes`). This is because the original ResNet50 was trained on a dataset with 1,000 classes, but we only have 10 classes.\r\n",
    "  - We define our loss function to be cross entropy loss, which is commonly used for multi-class classification problems.\r\n",
    "  - We also set the learning rate and optimizer type, which will be used in training the model.\r\n",
    "\r\n",
    "- **`forward`**: This function defines the forward pass of the network, which simply calls the forward pass of the ResNet50 model.\r\n",
    "\r\n",
    "- **`training_step`**: This function defines what happens in each step of the training. For each batch, it computes the model's predictions (`logits`), calculates the loss between the predictions and the actual labels (`y`), logs the loss, and returns it.\r\n",
    "\r\n",
    "- **`validation_step`**: This function is similar to `training_step`, but is used during the validation phase. In addition to computing and returning the loss, it also adds each batch's loss to `self.val_losses`.\r\n",
    "\r\n",
    "- **`on_validation_epoch_end`**: This function is called at the end of each validation epoch. It calculates the average validation loss over all batches, logs it, and resets `self.val_losses`.\r\n",
    "\r\n",
    "- **`configure_optimizers`**: This function defines the optimizer that will be used to train the model. It supports both SGD and Adam optimizers.\r\n",
    "\r\n",
    "The overall architecture of our model is based on ResNet50, but adapted to our specific task. It is important to note that deep learning models are highly flexible, and this architecture can be further modified and tuned to better fit the data and the problem at hand.\r\n",
    "\r\n",
    "In the context of **deep learning**, ResNet, or Residual Network, is a type of Convolutional Neural Network (CNN) architecture that was designed to enable hundreds or thousands of convolutional layers. While traditional neural networks would become impossible to train effectively as depth increases, ResNet mitigates this by introducing \"skip\" or \"shortcut\" connections (also known as residual connections) that allow the model to learn an identity function that ensures the higher layer will perform at least as well as the lower layer, and not worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLesionModel(pl.LightningModule):\n",
    "    def __init__(self, learning_rate: float, optimizer_type: str = 'Adam', num_classes: int = NUM_CLASSES):\n",
    "        super().__init__()\n",
    "\n",
    "        # Use a pre-trained ResNet50 model\n",
    "        self.model = torchvision.models.resnet50(pretrained=True)\n",
    "        # Replace the last layer to match the number of classes\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "        # Cross entropy loss\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Optimizer type\n",
    "        self.optimizer_type = optimizer_type\n",
    "\n",
    "        # Initialize a list to hold validation losses of each batch\n",
    "        self.val_losses = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.val_losses.append(loss)  # Append the loss of each batch to the list\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Calculate the mean loss of all batches and log it\n",
    "        avg_loss = torch.stack(self.val_losses).mean()\n",
    "        self.log('avg_val_loss', avg_loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.val_losses = []  # Reset the list for the next epoch\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.optimizer_type.lower() == 'sgd':\n",
    "            optimizer = SGD(self.parameters(), lr=self.learning_rate)\n",
    "        elif self.optimizer_type.lower() == 'adam':\n",
    "            optimizer = Adam(self.parameters(), lr=self.learning_rate)\n",
    "        else:\n",
    "            raise ValueError(f'Optimizer type {self.optimizer_type} not recognized')\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the Dataset**\n",
    "\n",
    "Machine Learning models learn from data. In PyTorch, we often use `Dataset` and `DataLoader` classes to manage our data, divide it into batches, shuffle it, and allow for multi-threaded data loading.\n",
    "\n",
    "Here, we define a `DeepLesionDataset` class that inherits from `torch.utils.data.Dataset`. This class is responsible for loading the images and their corresponding labels from disk. Let's discuss each part:\n",
    "\n",
    "- **`__init__`**: This function is called when we create a new instance of the class. We pass in the image directory, a pandas DataFrame containing the metadata of the dataset (such as file names and labels), and any image transformations we want to apply.\n",
    "\n",
    "- **`__len__`**: This function returns the total number of samples in our dataset. It's used by PyTorch to determine the number of steps per epoch.\n",
    "\n",
    "- **`__getitem__`**: This function is called to get the sample and label at a particular index. We:\n",
    "  - Open the image file and convert it to a 16-bit grayscale image.\n",
    "  - Apply a linear transformation to convert the pixel values to Hounsfield Units (used in medical imaging to quantify radiodensity), which improves the contrast in the images.\n",
    "  - Apply DICOM windowing: DICOM is a standard used in medical imaging. Different tissues (like bones, blood, etc.) have different ranges of Hounsfield Units. Windowing allows us to focus on a specific range, which enhances the visibility of certain tissues over others.\n",
    "  - Clip the image pixel values to lie within the DICOM window and scale them to range from 0 to 255.\n",
    "  - Convert the image to a PIL Image object and apply any transformations.\n",
    "  - Retrieve the label from the DataFrame, adding 1 because our lesion types are from -1 to 8 and we need them to be from 0 to 9.\n",
    "\n",
    "**Note**: The specific preprocessing and transformations applied to the images are due to the nature of medical imaging data. Different types of data would require different preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLesionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dir, df, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row['File_name'])\n",
    "        image = Image.open(img_path).convert('I')  # 16-bit image\n",
    "        image = np.array(image, dtype=np.int32)\n",
    "        image -= 32768  # Convert pixel values to Hounsfield Units (HU)\n",
    "\n",
    "        # Apply DICOM windowing\n",
    "        min_val, max_val = map(float, row['DICOM_windows'].split(','))\n",
    "        image = np.clip(image, min_val, max_val)\n",
    "        image = (image - min_val) / (max_val - min_val) * 255\n",
    "        image = image.astype(np.uint8)  # Convert to 8-bit\n",
    "\n",
    "        # Convert back to PIL image\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Get label\n",
    "        label = row['Coarse_lesion_type'] + 1\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the DataModule**\r\n",
    "\r\n",
    "While the `Dataset` class in PyTorch is responsible for how to load a single sample, `DataModule` in PyTorch Lightning is a more high-level construct. It organizes all data loading and preparation steps, and it's compatible with the Lightning Trainer for maximum convenience. \r\n",
    "\r\n",
    "Our `DeepLesionDataModule` class inherits from `pl.LightningDataModule`. Let's break down the parts:\r\n",
    "\r\n",
    "- **`__init__`**: When creating a new instance, we pass in the path to the data directory, the path to the CSV file with labels, the image transformations, and the batch size.\r\n",
    "\r\n",
    "- **`setup`**: This method is called to prepare the data for use. Here, we create our training and validation datasets. We use a DataFrame loaded from the CSV file and create two new DataFrames for training and validation data based on the 'Train_Val_Test' column. Then, we use these DataFrames to instantiate our `DeepLesionDataset` for training and validation.\r\n",
    "\r\n",
    "- **`train_dataloader` and `val_dataloader`**: These methods return the DataLoaders that will be used for training and validation, respectively. They use the `DataLoader` class from PyTorch to combine the dataset into batches and allow for multi-threaded or multi-process data loading.\r\n",
    "\r\n",
    "In the next part of the cell, we define a custom transform class `To3Channels` that converts a 1-channel grayscale image to a 3-channel image by duplicating the channel three times. We need this because the ResNet model we are using is designed for 3-channel RGB images.\r\n",
    "\r\n",
    "The `transforms.Compose` function allows us to chain multiple transformations together. We resize the image to match the input size expected by our model, convert it to a tensor, duplicate the grayscale channel to make it a 3-channel image, and normalize it using the mean and standard deviation values of ImageNet (since our ResNet model was pre-trained on ImageNet).\r\n",
    "\r\n",
    "Finally, we instantiate our `DeepLesionDataModule` with the appropriate parameters and call `setup()` to prepare our data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DataModule\n",
    "class DeepLesionDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir, csv_path, transform, batch_size=BATCH_SIZE):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.csv_path = csv_path\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Instantiate the full dataset\n",
    "        full_dataset = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Filter rows to create training and validation datasets based on the 'Train_Val_Test' column\n",
    "        train_df = full_dataset[full_dataset['Train_Val_Test'] == 1]\n",
    "        val_df = full_dataset[full_dataset['Train_Val_Test'] == 2]\n",
    "\n",
    "        # Create the train and val datasets\n",
    "        self.train_dataset = DeepLesionDataset(self.data_dir, train_df, transform=self.transform)\n",
    "        self.val_dataset = DeepLesionDataset(self.data_dir, val_df, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=8)\n",
    "\n",
    "class To3Channels(object):\n",
    "    \"\"\"Convert a 1-channel grayscale image to a 3-channel image by duplicating the channel three times.\"\"\"\n",
    "    def __call__(self, image):\n",
    "        return image.repeat(3, 1, 1)\n",
    "\n",
    "\n",
    "# Create the transform\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "    To3Channels(),  # Expand to 3 channels\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)  # Normalize with ImageNet mean and std\n",
    "])\n",
    "\n",
    "# Instantiate the datamodule\n",
    "data_module = DeepLesionDataModule(KEY_DATA_DIR, CSV_PATH, transform=transformer)\n",
    "data_module.setup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Callbacks**\r\n",
    "\r\n",
    "A *callback* is a piece of code that can be specified to be executed at certain stages of the training process, such as at the start or end of an epoch, on batch start or end, etc. PyTorch Lightning provides a variety of built-in callbacks for common uses.\r\n",
    "\r\n",
    "Here we are configuring four types of callbacks:\r\n",
    "\r\n",
    "- **EarlyStopping**: This callback monitors a specified metric (in this case, the validation loss), and stops the training process when the metric stops improving. This is useful to prevent overfitting. We have set a patience of 3, which means training will stop if the validation loss does not improve for 3 consecutive epochs. The `mode=\"min\"` argument indicates that improvement is defined as a decrease in the metric value.\r\n",
    "\r\n",
    "- **ModelCheckpoint**: This callback saves the model weights at certain intervals. We are monitoring the validation loss and saving the weights of the model whenever the validation loss reaches a new minimum. We specify a directory to save the checkpoints and a filename template that includes the epoch number and validation loss. The `save_top_k=3` argument means that the best 3 models (with the lowest validation loss) will be saved.\r\n",
    "\r\n",
    "- **DeviceStatsMonitor**: This callback logs device (GPU or CPU) usage statistics such as memory and utilization during training. This can be useful to track resource usage, identify bottlenecks, and ensure that the training process is making efficient use of the available hardware.\r\n",
    "\r\n",
    "- **LearningRateMonitor**: This callback logs the learning rate for TensorBoard. This is useful if you're using a learning rate scheduler that changes the learning rate during training, as you can see how the learning rate changes and how it correlates with other metrics like loss.\r\n",
    "\r\n",
    "These callbacks are passed to the `Trainer` when it is instantiated, and they are called at the appropriate times during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure early stopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", # or the metric of your choice\n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "# Configure model checkpointing\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\", # or the metric of your choice\n",
    "    dirpath=\".training_checkpoints\",\n",
    "    filename=\"model-{epoch:02d}-{val_loss:.2f}\", # or use a custom template of your choice\n",
    "    save_top_k=3,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "device_stats_callback = DeviceStatsMonitor()\n",
    "\n",
    "learning_rate_callback = LearningRateMonitor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Launching TensorBoard**\n",
    "\n",
    "TensorBoard is a powerful tool that provides a range of functionalities for visualizing deep learning models, metrics, and more. It's designed to help you understand, debug, and optimize your model by displaying scalars, images, text, graphs, histograms, etc.\n",
    "\n",
    "In this cell, we are doing two things:\n",
    "\n",
    "- The `%load_ext tensorboard` magic command loads the TensorBoard extension for Jupyter notebooks. It's a one-time setup step that allows us to launch TensorBoard inside the notebook.\n",
    "\n",
    "- The `%tensorboard --logdir ./tb_logs` magic command actually starts TensorBoard. The `--logdir` argument specifies the directory where TensorBoard should look for log files to display. We've logged our training and validation metrics to this directory using the `TensorBoardLogger` when we defined our `Trainer`.\n",
    "\n",
    "So, with just two lines of code, we're starting a comprehensive real-time visualization suite right inside our notebook! As your model trains, you'll be able to track its performance, view the learning curves, analyze the gradient flow, understand your model architecture, and much more. TensorBoard can be an invaluable tool in your machine learning toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-632cd670a998f5ab\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-632cd670a998f5ab\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./tb_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\r\n",
    "In this final cell, we're putting together everything we've built and defined in the previous steps to actually train our neural network model.\r\n",
    "\r\n",
    "First, we instantiate our `DeepLesionModel` which we defined earlier. We specify the number of lesion classes and the learning rate as arguments. These are defined as constants at the top of the notebook. \r\n",
    "\r\n",
    "Next, we define a `Trainer` using PyTorch Lightning. This is where a lot of the magic happens. The `Trainer` abstracts away a lot of the boilerplate training code you would usually write when using vanilla PyTorch. Here are the components we define for our `Trainer`:\r\n",
    "\r\n",
    "1. `max_epochs`: The maximum number of complete passes through the training dataset before stopping the training process.\r\n",
    "\r\n",
    "2. `callbacks`: These are special functions that the `Trainer` will call at specific points during training. We include the early stopping and model checkpointing callbacks we defined earlier, along with device stats and learning rate monitoring.\r\n",
    "\r\n",
    "3. `accelerator`, `strategy`, and `devices`: These are configurations for how PyTorch Lightning should distribute the computation. Setting these to \"auto\" allows PyTorch Lightning to make the best decision based on your available hardware.\r\n",
    "\r\n",
    "4. `logger`: This is for logging training/validation metrics and parameters to a format that can be visualized in TensorBoard. We point it to a directory called `tb_logs` and give our training run a name: \"deep_lesion\".\r\n",
    "\r\n",
    "Finally, we call `trainer.fit(model, data_module)` to kick off the training process. This will start the process of running our images through the model, adjusting the model's weights based on the output, and repeating this process across the number of epochs we've specified. During this process, you can watch the training and validation loss values (a measure of how well the model is performing) go down, hopefully indicating that our model is learning to classify lesion types from our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbourne/anaconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jbourne/anaconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | ResNet           | 23.5 M\n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.114    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016a4ce50512493cbd7e3ae485e6695f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 20.603\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbourne/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = DeepLesionModel(num_classes=NUM_CLASSES, learning_rate=LEARNING_RATE)\n",
    "\n",
    "# Define PyTorch Lightning trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        early_stop_callback,\n",
    "        checkpoint_callback,\n",
    "        device_stats_callback,\n",
    "        learning_rate_callback,\n",
    "    ],\n",
    "    accelerator=\"auto\",\n",
    "    strategy=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    logger=TensorBoardLogger(\"tb_logs\", name=\"deep_lesion\") # Use TensorBoard to log the metrics\n",
    ")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_lesion",
   "language": "python",
   "name": "deep_lesion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
