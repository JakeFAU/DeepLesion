{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment\r\n",
    "\r\n",
    "Before we get started, we need to install several Python packages that we'll use throughout this notebook. \r\n",
    "\r\n",
    "1. **torch and torchvision**: PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab. Torchvision is a package that provides access to popular datasets, model architectures, and image transformations for computer vision.\r\n",
    "\r\n",
    "2. **pytorch-lightning and pytorch-lightning-bolts**: PyTorch Lightning is a lightweight PyTorch wrapper for high-performance AI research. It structures your code so it's decoupled and reusable, while ensuring all the right best practices are applied. PyTorch Lightning Bolts is a collection of PyTorch Lightning implementations of popular models, so you don't have to start from scratch.\r\n",
    "\r\n",
    "3. **torchmetrics**: A library that provides easy access to various evaluation metrics in PyTorch.\r\n",
    "\r\n",
    "4. **tensorboard-plugin-profile**: A plugin for TensorBoard, a tool for providing the measurements and visualizations needed during the machine learning workflow. This plugin specifically provides the capability to profile your TensorFlow or PyTorch training jobs.\r\n",
    "\r\n",
    "5. **numpy, pandas, matplotlib, seaborn**: Widely used Python libraries for data manipulation, analysis, and visualization.\r\n",
    "\r\n",
    "6. **opencv-python**: A Python wrapper for the original OpenCV library which is an open source computer vision and machine learning software library.\r\n",
    "\r\n",
    "7. **scikit-learn**: A machine learning library for Python that features various algorithms like support vector machine, random forests, and k-neighbours, and it also supports Python numerical and scientific libraries like NumPy and SciPy.\r\n",
    "\r\n",
    "8. **tensorboardX, tensorboard**: TensorBoard provides the visualization and tooling needed for machine learning experimentation. TensorBoardX is a nice interface communicating TensorBoard, allowing users to log PyTorch models and metrics into a format TensorBoard understands.\r\n",
    "\r\n",
    "9. **tqdm**: A Python library that provides fast, extensible progress bars for loops.\r\n",
    "\r\n",
    "In the code cell below, we install these packages using pip, Python's package manager. The exclamation point at the beginning of each line tells Jupyter Notebook to execute the line as a shell command.\r\n",
    "\r\n",
    "After installing the packages, we enable the inline backend for matplotlib with the magic command `%matplotlib inline`. This makes matplotlib plots appear inline within the notebook, directly below the codld our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision pytorch-lightning pytorch-lightning-bolts torchmetrics tensorboard-plugin-profile\n",
    "!pip install numpy pandas matplotlib opencv-python scikit-learn tensorboardX tensorboard tqdm seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Next, we import the necessary libraries. \n",
    "\n",
    "1. **Standard library**: We import `os` and `random` from Python's standard library. `os` allows us to interact with the operating system, while `random` allows us to generate random numbers.\n",
    "\n",
    "2. **Third-party libraries**: We import a number of third-party libraries for various purposes. `numpy` and `pandas` are for data manipulation and analysis. `matplotlib` and `seaborn` are for data visualization. `PIL` (Pillow) is for opening, manipulating, and saving many different image file formats. `sklearn.model_selection` provides functions to split the dataset into training set and test set. `sklearn.metrics` provides functions to calculate the Mean Squared Error, Mean Absolute Error, and the R2 Score, which are common metrics used in regression problems. `tqdm` provides progress bars for visualizing the status of loops.\n",
    "\n",
    "3. **PyTorch and related libraries**: `torch` is the main PyTorch library, and `torch.nn` and `torch.nn.functional` provide classes and functions for building neural networks. `torch.optim` provides classes for various optimization algorithms.\n",
    "\n",
    "4. **torchvision**: `torchvision` provides utilities for working with image data, including pre-trained models, utilities for image transformation, and popular datasets.\n",
    "\n",
    "5. **PyTorch Lightning**: We use PyTorch Lightning, a lightweight wrapper around PyTorch, to organize our machine learning code. It provides classes for defining machine learning models, managing data, and training models.\n",
    "\n",
    "6. **Torchmetrics**: A library that provides easy access to various evaluation metrics in PyTorch.\n",
    "\n",
    "Note: The command `os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'` is used to limit TensorFlow debugging output to ERROR level. This isn't necessary if you're not using TensorFlo's included here in case you decide to use it in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # To limit TensorFlow debugging output\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score  # Sklearn metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch and related libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, DeviceStatsMonitor, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# Torchmetrics\n",
    "import torchmetrics  \n",
    "from torchmetrics import MeanSquaredError, MeanAbsoluteError  \n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# Print versions\n",
    "print(f\"Torchvision: {torchvision.__version__}\")\n",
    "print(f\"PyTorch Lightning: {pl.__version__}\")  # <--- TYPO FIX\n",
    "print(f\"Torch: {torch.__version__}\")\n",
    "print(f\"Numpy: {np.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"Torchmetrics: {torchmetrics.__version__}\")  # Print torchmetrics version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "\n",
    "In this section, we define the constants that we'll use in our code. \n",
    "\n",
    "1. **Paths**: We define the path to the directory where our data is stored, the path to the directory where our key slices are stored, and the path to the CSV file containing our labels.\n",
    "\n",
    "2. **Image settings**: We define the size of the images we'll be working with, and the number of classes in our data. We also assume that the grayscale images have been standardized to have values between 0 and 1, and so we define the mean and standard deviation of these grayscale images.\n",
    "\n",
    "3. **Training settings**: We define the batch size for training and validation, the number of epochs for training, the learning rate for the optimizer, the proportion of data to use for training (with the rest being used for validation), and the number of CPU cores to useOptimizer settings. \n",
    "\n",
    "4. **Optimizer settings**: We define the optimizer to use.e set correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# Path to data\n",
    "DATA_DIR: str = os.path.join(os.getcwd(), 'data/Images_png')\n",
    "KEY_DATA_DIR: str = os.path.join(os.getcwd(), 'data/Key_slices')\n",
    "CSV_PATH: str = os.path.join(os.getcwd(), 'data/DL_info.csv')  # The path to the CSV file containing the labels\n",
    "\n",
    "# Image settings\n",
    "IMAGE_SIZE: int = 224  # We will resize all images to this size. ResNet, for example, expects this input size\n",
    "NUM_CLASSES: int = 4   # the bounding box\n",
    "\n",
    "# Assume the grayscale images have been standardized to have values between 0 and 1\n",
    "GRAYSCALE_MEAN = 0.5\n",
    "GRAYSCALE_STD = 0.5\n",
    "\n",
    "# Training settings\n",
    "BATCH_SIZE: int = 32  # The batch size for training and validation\n",
    "EPOCHS: int = 200  # The number of epochs for training. Adjust based on your observation of the model performance\n",
    "LEARNING_RATE: float = 1e-3  # Learning rate for the optimizer. This may need to be adjusted based on the model's performance\n",
    "TRAIN_SPLIT: float = 0.8  # The proportion of data to use for training. The rest will be used for validation\n",
    "CPU_CORES: int = 8\n",
    "\n",
    "# Optimizer settings\n",
    "OPTIMIZER: str = 'Adam'  # The optimizer to use. You can change this to 'SGD' or other optimizers as needed\n",
    "LR_MODE: str = 'min'\n",
    "LR_FACTOR: float = 0.1\n",
    "LR_PATIENCE: int = 3\n",
    "ES_PATIENCE: int = 5\n",
    "\n",
    "# Print to check if the paths and values are correct\n",
    "print(DATA_DIR)\n",
    "print(KEY_DATA_DIR)\n",
    "print(CSV_PATH)\n",
    "print(BATCH_SIZE)\n",
    "print(EPOCHS)\n",
    "print(OPTIMIZER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions and Data Visualization\n",
    "\n",
    "In this section, we define some helper functions for our work. \n",
    "\n",
    "1. **`bbox_iou(box1, box2)`**: This function calculates the Intersection over Union (IoU) of two bounding boxes. IoU is a measure of the overlap between two bounding boxes. It is used in object detection to measure the accuracy of the predicted bounding box against the ground truth bounding box.\n",
    "\n",
    "2. **`visualize_and_print_stats(image)`**: This function displays an image and prints its minimum, maximum, mean, and standard deviation values. This is a useful tool for exploring your data and understanding its properties.\n",
    "\n",
    "3. **`To3Channels(object)`**: This is a class that defines a callable object to convert a 1-channel grayscale image to a 3-channel image by duplicating the channel three times. This is useful when working with models that expect 3-channel input.\n",
    "\n",
    "Lastly, we display a random image from the dataset to understand what kind of data we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Returns the IoU of two bounding boxes.\n",
    "    \"\"\"\n",
    "    # Obtain the intersection coordinates\n",
    "    x1 = torch.max(box1[..., 0], box2[..., 0])\n",
    "    y1 = torch.max(box1[..., 1], box2[..., 1])\n",
    "    x2 = torch.min(box1[..., 2], box2[..., 2])\n",
    "    y2 = torch.min(box1[..., 3], box2[..., 3])\n",
    "\n",
    "    # Compute the area of intersection\n",
    "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "\n",
    "    # Compute the area of both bounding boxes\n",
    "    box1_area = (box1[..., 2] - box1[..., 0]) * (box1[..., 3] - box1[..., 1])\n",
    "    box2_area = (box2[..., 2] - box2[..., 0]) * (box2[..., 3] - box2[..., 1])\n",
    "\n",
    "    # Compute the IoU\n",
    "    iou = intersection / (box1_area + box2_area - intersection + 1e-6)\n",
    "    \n",
    "    return iou\n",
    "\n",
    "\n",
    "def visualize_and_print_stats(image):\n",
    "    \"\"\"Display an image and print its min, max, mean, and std.\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Image min: {image.min()}\")\n",
    "    print(f\"Image max: {image.max()}\")\n",
    "    print(f\"Image mean: {image.mean()}\")\n",
    "    print(f\"Image std: {image.std()}\")\n",
    "\n",
    "class To3Channels(object):\n",
    "    \"\"\"Convert a 1-channel grayscale image to a 3-channel image by duplicating the channel three times.\"\"\"\n",
    "    def __call__(self, image):\n",
    "        return image.repeat(3, 1, 1)\n",
    "\n",
    "# Get the list of images\n",
    "images = os.listdir(KEY_DATA_DIR)\n",
    "\n",
    "# Choose a random image\n",
    "image = random.choice(images)\n",
    "\n",
    "# Load the image\n",
    "path = os.path.join(KEY_DATA_DIR, image)\n",
    "\n",
    "# Show the image\n",
    "image = Image.open(path)\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the DeepLesionModel\n",
    "\n",
    "The `DeepLesionModel` class inherits from the `pl.LightningModule` which is a part of the PyTorch Lightning library. This library is a lightweight PyTorch wrapper for high-performance AI research. The class contains several methods that serve different purposes in the process of training a deep learning model.\n",
    "\n",
    "Here are the methods explained:\n",
    "\n",
    "### `__init__`\n",
    "This method is used to initialize the `DeepLesionModel` object. The initialization involves setting up the base model, which in this case is the DenseNet121, a convolutional neural network that has achieved state-of-the-art performance on several benchmark datasets. The pretrained DenseNet121 model's fully connected layer is replaced with a new fully connected layer that is designed to output 4 values which correspond to the coordinates of the bounding box (x, y, width, height).\n",
    "\n",
    "Also, the Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), Symmetric Mean Absolute Percentage Error (SMAPE), and Mean Squared Logarithmic Error (MSLE) metrics are initialized in this method. These metrics are used to evaluate the performance of the model during the training and validation process.\n",
    "\n",
    "### `forward`\n",
    "This method defines the forward propagation process of the neural network. In this case, it simply involves passing the input tensor `x` through the base model.\n",
    "\n",
    "### `training_step`\n",
    "This method defines a single step in the training process. The input tensor `x` is passed through the model, and the output is compared to the target tensor `y` to calculate the loss. The loss is logged for tracking purposes. Additionally, metrics such as MAE, MAPE, SMAPE, MSLE, and Intersection over Union (IoU) are computed for the predictions and logged.\n",
    "\n",
    "### `on_train_epoch_end`\n",
    "At the end of each training epoch, this method computes and logs the average training loss for that epoch.\n",
    "\n",
    "### `validation_step`\n",
    "This method is similar to `training_step`, but it is used during the validation phase of the training process. The loss and metrics computed are based on the model's performance on the validation set.\n",
    "\n",
    "### `on_validation_epoch_end`\n",
    "This method is called at the end of each validation epoch and computes the average validation loss for the epoch, which is then logged.\n",
    "\n",
    "### `test_step`\n",
    "This method is called for each batch of the test dataset. It is similar to `training_step` and `validation_step`, but it's used for evaluating the model's performance on the unseen test data. The computed loss and metrics are logged.\n",
    "\n",
    "### `configure_optimizers`\n",
    "This method is used to specify the optimizer used during training. In this case, the Adam optimizer is used with a specified learning rate.\n",
    "\n",
    "### `prepare_data`\n",
    "This method is used to prepare the datasets for training, validation, and testing. The data is read from a CSV file and split according to the 'Train_Val_Test' column in the data. A `DeepLesionDataset` object is created for each split of the data, and a series of transforms are applied to the images, including converting the images to tensors and normalizing the pixel values.\n",
    "\n",
    "### `train_dataloader`, `val_dataloader`, `test_dataloader`\n",
    "These methods return PyTorch DataLoader objects for the training, validation, and test sets, respectively. These DataLoader objects are used to load the data in batches during the training, validation, and testing phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLesionModel(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=LEARNING_RATE, batch_size=32):\n",
    "        super().__init__()\n",
    "\n",
    "        # Base model (DenseNet121)\n",
    "        self.base_model = densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "        num_features = self.base_model.classifier.in_features\n",
    "\n",
    "        # Replace the fully connected layer for bounding box regression\n",
    "        self.base_model.classifier = torch.nn.Linear(num_features, 4)\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # metrics\n",
    "        self.mae = torchmetrics.MeanAbsoluteError()\n",
    "        self.mape = torchmetrics.MeanAbsolutePercentageError()\n",
    "        self.smape = torchmetrics.SymmetricMeanAbsolutePercentageError()\n",
    "        self.mlse = torchmetrics.MeanSquaredLogError()\n",
    "\n",
    "        # placeholders for losses\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        \n",
    "        loss = F.smooth_l1_loss(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        self.training_step_outputs.append(loss)\n",
    "        \n",
    "        # Calculate metrics on the train set\n",
    "        self.log(\"train_mae\", self.mae(y_hat, y))\n",
    "        self.log(\"train_mape\", self.mape(y_hat, y))\n",
    "        self.log(\"train_smape\", self.smape(y_hat, y))\n",
    "        self.log(\"train_mlse\", self.mlse(y_hat, y))\n",
    "    \n",
    "        iou = bbox_iou(y_hat, y).mean()\n",
    "        self.log('train_iou', iou)\n",
    "    \n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        epoch_average = torch.stack(self.training_step_outputs).mean()\n",
    "        self.log(\"train_loss_epoch\", epoch_average)\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        val_loss = F.smooth_l1_loss(y_hat, y)\n",
    "        self.log('val_loss', val_loss)\n",
    "        self.validation_step_outputs.append(val_loss)\n",
    "        \n",
    "        # Calculate metrics on the validation set\n",
    "        self.log(\"val_mae\", self.mae(y_hat, y))\n",
    "        self.log(\"val_mape\", self.mape(y_hat, y))\n",
    "        self.log(\"val_smape\", self.smape(y_hat, y))\n",
    "        self.log(\"val_mlse\", self.mlse(y_hat, y))\n",
    "\n",
    "        iou = bbox_iou(y_hat, y).mean()\n",
    "        self.log('val_iou', iou)\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        epoch_average = torch.stack(self.validation_step_outputs).mean()\n",
    "        self.log(\"val_loss_epoch\", epoch_average)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        test_loss = F.smooth_l1_loss(y_hat, y)\n",
    "        self.log('test_loss', test_loss)\n",
    "\n",
    "        # Calculate metrics on the test set\n",
    "        self.log(\"test_mae\", self.mae(y_hat, y))\n",
    "        self.log(\"test_mape\", self.mape(y_hat, y))\n",
    "        self.log(\"test_smape\", self.smape(y_hat, y))\n",
    "        self.log(\"test_mlse\", self.mlse(y_hat, y))\n",
    "        \n",
    "        iou = bbox_iou(y_hat, y).mean()\n",
    "        self.log('test_iou', iou)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        lr_scheduler = {\n",
    "            'scheduler': ReduceLROnPlateau(optimizer, mode=LR_MODE, factor=LR_FACTOR, patience=LR_PATIENCE),\n",
    "            'monitor': 'val_loss',  # metric to monitor for lr scheduling\n",
    "        }\n",
    "        return [optimizer], [lr_scheduler]\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        # Prepare the datasets here\n",
    "        full_dataset = pd.read_csv(CSV_PATH)  # replace with the path to your dataset\n",
    "    \n",
    "        train_df = full_dataset[full_dataset['Train_Val_Test'] == 1]\n",
    "        val_df = full_dataset[full_dataset['Train_Val_Test'] == 2]\n",
    "        test_df = full_dataset[full_dataset['Train_Val_Test'] == 3]\n",
    "    \n",
    "        self.train_dataset = DeepLesionDataset(\n",
    "            image_dir=KEY_DATA_DIR, \n",
    "            df=train_df, \n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([GRAYSCALE_MEAN], [GRAYSCALE_STD])\n",
    "            ])\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = DeepLesionDataset(\n",
    "            image_dir=KEY_DATA_DIR, \n",
    "            df=val_df, \n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([GRAYSCALE_MEAN], [GRAYSCALE_STD])\n",
    "            ])\n",
    "        )\n",
    "        \n",
    "        self.test_dataset = DeepLesionDataset(\n",
    "            image_dir=KEY_DATA_DIR, \n",
    "            df=test_df, \n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([GRAYSCALE_MEAN], [GRAYSCALE_STD])\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=CPU_CORES)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=CPU_CORES)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=CPU_CORES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Transformation\n",
    "\n",
    "These classes are related to the preparation and transformation of the data used to train the DeepLesion model.\n",
    "\n",
    "### `ResizeAndAdjustBbox`\n",
    "This class is a transformation that resizes an image and its corresponding bounding box. The bounding box is a rectangle that encapsulates the region of interest in an image (in this case, the lesion). When an image is resized, the coordinates of the bounding box also need to be adjusted to fit the new image size.\n",
    "\n",
    "The `__call__` method of the `ResizeAndAdjustBbox` class takes as input a tuple containing an image and its corresponding bounding box, resizes the image to the specified size, and adjusts the bounding box coordinates accordingly. The resized image and adjusted bounding box are returned.\n",
    "\n",
    "### `DeepLesionDataset`\n",
    "This class represents the dataset of images and their corresponding bounding boxes. This class inherits from the `torch.utils.data.Dataset` class which is an abstract class representing a dataset in PyTorch. This class is typically subclassed to create custom datasets.\n",
    "\n",
    "In the `__init__` method, the directory containing the images, the dataframe containing the image metadata (including bounding box coordinates), and the image transformations to apply are passed as arguments.\n",
    "\n",
    "The `__len__` method returns the number of images in the dataset.\n",
    "\n",
    "The `__getitem__` method is used to load and return an image and its corresponding bounding box from the dataset at the specified index. The image is loaded as a grayscale image, the bounding box is extracted from the dataframe, the `ResizeAndAdjustBbox` transform is applied to the image and bounding box, and any other specified transforms are applied to the image. The image and adjusted bounding box are then returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeAndAdjustBbox(object):\n",
    "    \"\"\"Resizes the image and adjusts the bounding box coordinates accordingly.\"\"\"\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, bbox = sample\n",
    "        w, h = image.size\n",
    "        new_w, new_h = self.size\n",
    "\n",
    "        # Resize the image\n",
    "        image = transforms.Resize(self.size)(image)\n",
    "\n",
    "        # Adjust the bounding box coordinates\n",
    "        bbox = [bbox[0]*new_w/w, bbox[1]*new_h/h, bbox[2]*new_w/w, bbox[3]*new_h/h]\n",
    "\n",
    "        return image, torch.tensor(bbox)\n",
    "\n",
    "class DeepLesionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dir, df, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.resize_and_adjust_bbox = ResizeAndAdjustBbox((IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row['File_name'])\n",
    "    \n",
    "        # Load the image as grayscale\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        image = np.array(image, dtype=np.uint8)\n",
    "        image = Image.fromarray(image)  # Convert back to PIL image\n",
    "    \n",
    "        # Get bounding box\n",
    "        bbox = list(map(float, row['Bounding_boxes'].split(',')))\n",
    "    \n",
    "        # Apply the resize and adjust bbox transform\n",
    "        image, bbox = self.resize_and_adjust_bbox((image, bbox))\n",
    "    \n",
    "        # Apply other transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, bbox\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Module Definition\n",
    "\n",
    "A PyTorch Lightning data module encapsulates the data loading and preparation process. It allows for easy reuse of data loading code across different models and also helps in ensuring that data-related code is organized and separated from model training code. \n",
    "\n",
    "The `DeepLesionDataModule` class is the data module for the DeepLesion model. It inherits from the `pl.LightningDataModule` class and defines methods for preparing the data and loading it into a format that can be used by PyTorch.\n",
    "\n",
    "In the `__init__` method, it takes in the directory containing the data, the path to the CSV file containing the metadata of the dataset, and the batch size to be used in training. It also defines the transformations to be applied to the images in the dataset. These transformations include converting the image to a PyTorch tensor, expanding it to 3 channels, and normalizing it with the mean and standard deviation values of the ImageNet dataset.\n",
    "\n",
    "In the `setup` method, it reads the CSV file to obtain the metadata of the dataset and filters the data to create training, validation, and testing datasets based on the 'Train_Val_Test' column. It then creates instances of the `DeepLesionDataset` class for each of these datasets.\n",
    "\n",
    "The `train_dataloader`, `val_dataloader`, and `test_dataloader` methods define the data loaders for the training, validation, and testing datasets respectively. These data loaders will provide batches of data to the model during training.\n",
    "\n",
    "Finally, an instance of the `DeepLesionDataModule` class is created and its `setup` method is called to prepare the data for training.\n",
    "\n",
    "This setup ensures that all the data-related logic is encapsulated within the data module, making it easy to use this data in different parts of the code and ensuring that the data preparation process is consistent across different runs of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define DataModule\n",
    "class DeepLesionDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir, csv_path, batch_size=BATCH_SIZE):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.csv_path = csv_path\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "            To3Channels(),  # Expand to 3 channels\n",
    "            transforms.Normalize(mean=[GRAYSCALE_MEAN, GRAYSCALE_MEAN, GRAYSCALE_MEAN], \n",
    "                                 std=[GRAYSCALE_STD, GRAYSCALE_STD, GRAYSCALE_STD])  # Normalize with grayscale mean and std\n",
    "        ])\n",
    "\n",
    "\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Instantiate the full dataset\n",
    "        full_dataset = pd.read_csv(self.csv_path)\n",
    "\n",
    "        # Filter rows to create training, validation and testing datasets based on the 'Train_Val_Test' column\n",
    "        train_df = full_dataset[full_dataset['Train_Val_Test'] == 1]\n",
    "        val_df = full_dataset[full_dataset['Train_Val_Test'] == 2]\n",
    "        test_df = full_dataset[full_dataset['Train_Val_Test'] == 3]\n",
    "\n",
    "        # Create the train, val and test datasets\n",
    "        self.train_dataset = DeepLesionDataset(self.data_dir, train_df, transform=self.transform)\n",
    "        self.val_dataset = DeepLesionDataset(self.data_dir, val_df, transform=self.transform)\n",
    "        self.test_dataset = DeepLesionDataset(self.data_dir, test_df, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=8)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=8)\n",
    "\n",
    "# Instantiate the datamodule\n",
    "data_module = DeepLesionDataModule(KEY_DATA_DIR, CSV_PATH)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks Definition\n",
    "\n",
    "Callbacks in PyTorch Lightning provide a way to hook into the model training process at specific points to execute some code. They can be used to implement a variety of functionalities such as saving checkpoints, adjusting the learning rate, or stopping training early when the model's performance has stopped improving.\n",
    "\n",
    "In the given code, several callbacks are defined:\n",
    "\n",
    "1. **Early Stopping:** The `EarlyStopping` callback is used to stop the training process early if the model's performance on the validation set (measured by the `val_loss`) doesn't improve by at least `0.001` for `3` consecutive epochs. This can help save time and computational resources by stopping the training when the model is no longer making significant improvements.\n",
    "\n",
    "2. **Model Checkpointing:** The `ModelCheckpoint` callback is used to save checkpoints of the model at the end of each epoch. The checkpoints are saved in the `.training_checkpoints` directory, with filenames given by the template `\"model-{epoch:02d}-{val_loss:.2f}\"`. The `save_top_k=3` argument means that only the best 3 checkpoints (measured by the `val_loss`) will be saved, and older checkpoints will be deleted. Checkpoints allow us to resume training from a certain point or to use the saved model weights for evaluation or inference later.\n",
    "\n",
    "3. **Device Stats Monitor:** The `DeviceStatsMonitor` callback is used to log device-specific stats, such as GPU utilization and memory usage, for every training step. This can be useful for profiling and understanding resource utilization.\n",
    "\n",
    "4. **Learning Rate Monitor:** The `LearningRateMonitor` callback is used to log the learning rate for each epoch. This can be useful for understanding how the learning rate changes over the course of training, especially if a learning rate scheduler is used.\n",
    "\n",
    "These callbacks are added to the trainer when it is created, and they will automatically execute their code at the appropriate points during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the specific UserWarning related to the checkpoint directory\n",
    "warnings.filterwarnings(\n",
    "    action='ignore',\n",
    "    category=UserWarning,\n",
    "    module='pytorch_lightning.callbacks.model_checkpoint',\n",
    "    message='.*Checkpoint directory.*exists and is not empty.*',\n",
    ")\n",
    "\n",
    "# Configure early stopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", # or the metric of your choice\n",
    "    min_delta=0.001,\n",
    "    patience=ES_PATIENCE,\n",
    "    verbose=True,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "# Configure model checkpointing\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\", # or the metric of your choice\n",
    "    dirpath=\".training_checkpoints\",\n",
    "    filename=\"model-{epoch:02d}-{val_loss:.2f}\", # or use a custom template of your choice\n",
    "    save_top_k=3,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "device_stats_callback = DeviceStatsMonitor()\n",
    "\n",
    "learning_rate_callback = LearningRateMonitor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard and Magic Commands in Jupyter\n",
    "\n",
    "TensorBoard is a handy tool that comes with TensorFlow, and it provides a suite of web applications for inspecting and understanding your model runs and graphs. You can track and visualize various metrics such as loss and accuracy, display images, text, and more - all within an interactive web interface.\n",
    "\n",
    "In the Jupyter notebook, magic commands are enhancements added on top of the normal Python syntax and are prefixed by the '%' character. These magic commands are intended to solve common problems in data analysis using Python. For instance, magic commands can write content of the cell to a file, change the directory, load a script into a code cell, run a code cell, load an extension enabling extra functionality, etc.\n",
    "\n",
    "There are two kinds of magic commands:\n",
    "\n",
    "1. Line magics: These are commands prepended by one % character and are executed within the context of a single line of input.\n",
    "\n",
    "2. Cell magics: These are commands that start with a double %% and they operate on multiple lines of input.\n",
    "\n",
    "In the context of your code,\n",
    "\n",
    "- `%load_ext tensorboard` is a line magic command that loads the tensorboard extension. This command needs to be run only once in a Jupyter notebook. The `load_ext` command is a shorthand for `Load IPython extension to load extensions by their module name.`\n",
    "\n",
    "- `%tensorboard --logdir ./tb_logs` is another line magic command that launches TensorBoard within the notebook, specifying the log directory as `./tb_logs`. This directory contains the logs that are generated by TensorBoard while running and it will monitor this directory to track real-time changes.\n",
    "\n",
    "To sum it up, the use of these two magic commands in Jupyter provides an embedded, interactive interface to TensorBoard right within your Jupyter notebook, which is extremely handy for real-time visualization of training logs and other model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./tb_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "In this part, you're setting up the model training process. \n",
    "\n",
    "First, you instantiate your model `DeepLesionModel` with a specified learning rate. \n",
    "\n",
    "Next, you define a PyTorch Lightning `Trainer` which contains most of the boilerplate training loop logic. \n",
    "\n",
    "In the `Trainer`, you specify the following parameters:\n",
    "\n",
    "- `max_epochs`: The maximum number of epochs to train the model.\n",
    "- `callbacks`: Callbacks you created in the previous cells are specified here. They serve for early stopping, model checkpointing, monitoring device stats, and tracking learning rate.\n",
    "- `accumulate_grad_batches`: This is gradient accumulation. It is a simple trick to allow you to effectively batch your data in larger sets which can lead to more stable training dynamics.\n",
    "- `precision`: This is the precision of your model training. You're using mixed precision ('16-mixed') which can speed up the training and reduce memory usage without significant loss of model accuracy.\n",
    "- `accelerator`: The hardware accelerator to use for training, here it is set to automatically use available GPU(s) if available, else CPU.\n",
    "- `strategy`: Training strategy, here also set to automatic.\n",
    "- `devices`: Number of devices to train on (GPUs/TPUs), here also set to automatic.\n",
    "- `logger`: Logger to track the training progress. In this case, you're using a `TensorBoardLogger` which will log your metrics to a folder that can be visualized using TensorBoard.\n",
    "\n",
    "Then, you clear any cached memory with `torch.cuda.empty_cache()` to free up some GPU memory before training starts.\n",
    "\n",
    "Finally, you fit the model to your data by calling `trainer.fit(model, data_module)`. This starts the training process with the provided model and data. The `fit` function handles the full optimization routine: it initializes the optimizer, conducts the forward and backward passes through the network, updates the weights, and repeats the process for the specified number of epochs. The progress of training will be logged by the specified logger and can be visualized in real-time in TensorBoard. \n",
    "\n",
    "Remember that the training process can take a considerable amount of time depending on the complexity of your model, the amount of data you have, and the computational resources at your disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = DeepLesionModel(learning_rate=LEARNING_RATE)\n",
    "\n",
    "# Define PyTorch Lightning trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        early_stop_callback,\n",
    "        checkpoint_callback,\n",
    "        device_stats_callback,\n",
    "        learning_rate_callback,\n",
    "    ],\n",
    "    accumulate_grad_batches=4,\n",
    "    precision='16-mixed',\n",
    "    accelerator=\"auto\",\n",
    "    strategy=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    logger=TensorBoardLogger(\"tb_logs\", name=\"deep_lesion\") # Use TensorBoard to log the metrics\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, data_module)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing and Evaluation Metrics\n",
    "\n",
    "After training the model, you will want to test its performance on unseen data. You do this by calling the `trainer.test(model, datamodule=data_module)`. This will load the test data, feed it through the model, calculate the loss and the specified metrics, and log the results. \n",
    "\n",
    "Let's break down each of the metrics that are printed in the next few lines:\n",
    "\n",
    "1. `MAE` (Mean Absolute Error): This is an average of the absolute differences between the predictions and the actual values. It measures how close the predictions are to the actual values. The lower the MAE, the better the model's performance.\n",
    "\n",
    "2. `MAPE` (Mean Absolute Percentage Error): This is a measure of prediction accuracy of a forecasting method in statistics. It expresses the error as a percentage, providing a relative measure of the absolute error.\n",
    "\n",
    "3. `SMAPE` (Symmetric Mean Absolute Percentage Error): Similar to MAPE but it is symmetric. It can be better than MAPE when actual observation values are close to zero.\n",
    "\n",
    "4. `MLSE` (Mean Squared Logarithmic Error): This measures the ratio between the true and predicted values. It's useful when the target variable covers a large range of values.\n",
    "\n",
    "5. `IoU` (Intersection over Union): In the context of bounding boxes predictions, IoU measures the overlap between 2 boundaries. We use it to measure how close the predicted bounding box is to the actual bounding box. The higher the IoU, the better the model's performance in predicting bounding boxes.\n",
    "\n",
    "All these metrics together give a comprehensive understanding of the model's performance. Some models might perform better on one metric but worse on another, so it's useful to consider all these metrics together when evaluating the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "trainer.test(model, datamodule=data_module)\n",
    "\n",
    "# Access the logged test metrics\n",
    "print(f\"Test MAE: {trainer.logged_metrics['test_mae']}\")\n",
    "print(f\"Test MAPE: {trainer.logged_metrics['test_mape']}\")\n",
    "print(f\"Test SMAPE: {trainer.logged_metrics['test_smape']}\")\n",
    "print(f\"Test MLSE: {trainer.logged_metrics['test_mlse']}\")\n",
    "print(f\"Test IoU: {trainer.logged_metrics['test_iou']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Image, Ground Truth and Predicted Bounding Boxes\n",
    "\n",
    "The function `imshow` is used to display an image, along with the ground truth and predicted bounding boxes, if they are provided.\n",
    "\n",
    "The input to the function `inp` is a PyTorch tensor representing an image. If the image is grayscale, it first replicates the single channel to make it a 3-channel image (this is because Matplotlib expects either a single channel grayscale image or a 3-channel RGB image for display).\n",
    "\n",
    "The image tensor's values are then de-normalized using the mean and standard deviation values that were used for normalizing the original image. This is necessary because the original image was normalized (i.e., its pixel values were scaled down) before it was input to the model for training. We reverse this process to view the image in its original form for display.\n",
    "\n",
    "The `imshow` function can also optionally display the ground truth and the predicted bounding boxes. Bounding boxes are represented as `Rectangle` patches and are added to the image plot. The ground truth bounding box is displayed in red and the predicted bounding box is displayed in green.\n",
    "\n",
    "This function is helpful to visually inspect the performance of your model. You can see exactly where the model predicts a lesion to be and compare that with the actual lesion location. It helps you understand how well your model is doing and where it is making mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the test data\n",
    "test_inputs, test_classes = next(iter(data_module.test_dataloader()))\n",
    "\n",
    "# Generate 16 random indices\n",
    "random_indices = np.random.choice(len(test_inputs), size=16, replace=False)\n",
    "\n",
    "fig, axs = plt.subplots(4, 4, figsize=(20, 20))  # Create a 4x4 grid of subplots\n",
    "axs = axs.ravel()  # Flatten the grid to easily index into it\n",
    "\n",
    "for i, idx in enumerate(random_indices):  # Display 16 images\n",
    "    img = test_inputs[idx]\n",
    "    if img.shape[0] == 1:\n",
    "        img = img.expand((3, -1, -1))\n",
    "    # Compute predictions\n",
    "    with torch.no_grad():\n",
    "        predictions = model(img.unsqueeze(0)).squeeze(0)\n",
    "    \n",
    "    # Convert tensor to numpy array for display\n",
    "    inp = img.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([GRAYSCALE_MEAN, GRAYSCALE_MEAN, GRAYSCALE_MEAN])\n",
    "    std = np.array([GRAYSCALE_STD,GRAYSCALE_STD, GRAYSCALE_STD])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "\n",
    "    # Display the image in the subplot\n",
    "    axs[i].imshow(inp)\n",
    "    axs[i].axis('off')  # Hide the axes for this subplot\n",
    "\n",
    "    # Draw ground truth bounding box\n",
    "    gt_rect = patches.Rectangle((test_classes[idx][0], test_classes[idx][1]), \n",
    "                                test_classes[idx][2], test_classes[idx][3], linewidth=2, edgecolor='r', facecolor='none')\n",
    "    axs[i].add_patch(gt_rect)\n",
    "    \n",
    "    # Draw predicted bounding box\n",
    "    pred_rect = patches.Rectangle((predictions[0], predictions[1]), \n",
    "                                  predictions[2], predictions[3], linewidth=2, edgecolor='g', facecolor='none')\n",
    "    axs[i].add_patch(pred_rect)\n",
    "\n",
    "plt.tight_layout()  # Ensure the subplots do not overlap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_lesion",
   "language": "python",
   "name": "deep_lesion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
